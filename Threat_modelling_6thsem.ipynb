{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtEbIGJ9Fufo//LYweJ1Jg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UN85pWrpJEIg","executionInfo":{"status":"ok","timestamp":1752583964653,"user_tz":-330,"elapsed":31451,"user":{"displayName":"Keerthana Tadkal","userId":"05624686938958822678"}},"outputId":"41ed7058-166f-4cce-d80b-ffcd8d791685"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.94.0)\n","Collecting openai\n","  Downloading openai-1.95.1-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n","Collecting gradio\n","  Downloading gradio-5.37.0-py3-none-any.whl.metadata (16 kB)\n","Collecting pymongo\n","  Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n","Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n","Collecting brotli>=1.1.0 (from gradio)\n","  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.0)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n","Collecting gradio-client==1.10.4 (from gradio)\n","  Downloading gradio_client-1.10.4-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.2)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.4->gradio) (15.0.1)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n","  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading openai-1.95.1-py3-none-any.whl (755 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-5.37.0-py3-none-any.whl (59.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.10.4-py3-none-any.whl (323 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: brotli, dnspython, pymongo, openai, gradio-client, gradio\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.94.0\n","    Uninstalling openai-1.94.0:\n","      Successfully uninstalled openai-1.94.0\n","  Attempting uninstall: gradio-client\n","    Found existing installation: gradio_client 1.10.1\n","    Uninstalling gradio_client-1.10.1:\n","      Successfully uninstalled gradio_client-1.10.1\n","  Attempting uninstall: gradio\n","    Found existing installation: gradio 5.31.0\n","    Uninstalling gradio-5.31.0:\n","      Successfully uninstalled gradio-5.31.0\n","Successfully installed brotli-1.1.0 dnspython-2.7.0 gradio-5.37.0 gradio-client-1.10.4 openai-1.95.1 pymongo-4.13.2\n"]}],"source":["!pip install --upgrade openai gradio pymongo"]},{"cell_type":"markdown","source":["LLM-Setup"],"metadata":{"id":"aK9KlRwyLfrb"}},{"cell_type":"code","source":["import openai\n","\n","# Your API key\n","api_key =   # Replace with your OpenAI key\n","\n","client = openai.OpenAI(api_key=api_key)\n","\n","# Function to query ChatGPT\n","def query_chatgpt(prompt, model=\"gpt-4\", temperature=0.7):\n","    try:\n","        response = client.chat.completions.create(\n","            model=model,\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ],\n","            temperature=temperature,\n","            max_tokens=1024\n","        )\n","        return response.choices[0].message.content\n","    except Exception as e:\n","        return f\"Error: {str(e)}\"\n","\n","prompt = f\"\"\"what is can bus \"\"\"\n","print(query_chatgpt(prompt))\n"],"metadata":{"id":"zxgXyPipJKyf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset-ATT2.json"],"metadata":{"id":"724baCL2K4r5"}},{"cell_type":"code","source":["import ssl\n","import certifi\n","import json\n","from pymongo import MongoClient\n","\n","# MongoDB Atlas connection URI\n","MONGODB_URI = # Replace with your MONGODB URI\n","\n","# Connect to MongoDB\n","client = MongoClient(\n","    MONGODB_URI,\n","    tls=True,\n","    tlsCAFile=certifi.where()\n",")\n","\n","# Select database and collection\n","db = client[\"threat_db\"]\n","prompt_library = db[\"prompt_library\"]\n","\n","# 1. Predefined prompt templates with aliases\n","predefined_prompts = [\n","    {\n","        \"label\": \"can bus injection\",\n","        \"aliases\": [\"can bus\", \"controller area network\", \"can bus attack\", \"bus injection\"],\n","        \"prompt\": (\n","            \"\"\"Generate an attack tree for the Controller Area Network (CAN) bus in an automotive system. The root node should represent a successful attack on the CAN bus.\n","\n","The first level of branches should include:\n","- 'Message Injection',\n","- 'Denial of Service',\n","- 'Spoofing',\n","- 'Eavesdropping',\n","- 'Fault Injection',\n","- 'Firmware Manipulation',\n","- 'Physical Access'.\n","\n","Use Mermaid format with 'graph TD' syntax.\n","\n","For each branch, expand with at least two sub-branches on the second level, and for each of those sub-branches, add at least two further sub-branches on the third level, resulting in a three-level hierarchy in total.\n","\n","Specifically:\n","\n","- For 'Message Injection', include sub-branches 'Replay Attack' and 'Arbitrary Message Injection'. Then expand 'Replay Attack' with two sub-branches: 'Capturing Packets' and 'Resending Packets'. Expand 'Arbitrary Message Injection' with 'Crafting Messages' and 'Injecting Malicious Commands'.\n","\n","- For 'Denial of Service', include 'Bus Flooding' and 'Error Frame Injection'. Expand 'Bus Flooding' with 'Continuous Message Sending' and 'Resource Exhaustion'. Expand 'Error Frame Injection' with 'Error Frame Flood' and 'Bus Off State'.\n","\n","- For 'Spoofing', include 'ID Spoofing' and 'Timing Spoofing'. Expand 'ID Spoofing' with 'Forged IDs' and 'Masquerading'. Expand 'Timing Spoofing' with 'Delay Injection' and 'Replay Timing Manipulation'.\n","\n","- For 'Eavesdropping', include 'Passive Listening' and 'Data Capture'. Expand 'Passive Listening' with 'Bus Monitoring' and 'Signal Interception'. Expand 'Data Capture' with 'Message Logging' and 'Packet Analysis'.\n","\n","- For 'Fault Injection', include 'Voltage Manipulation' and 'Clock Glitching'. Expand 'Voltage Manipulation' with 'Power Supply Interruption' and 'Voltage Spike'. Expand 'Clock Glitching' with 'Clock Signal Interference' and 'Timing Violation'.\n","\n","- For 'Firmware Manipulation', include 'Malicious Firmware Update' and 'Firmware Downgrade'. Expand 'Malicious Firmware Update' with 'Tampered Firmware File' and 'OTA Exploitation'. Expand 'Firmware Downgrade' with 'Rollback Exploit' and 'Signature Bypass'.\n","\n","- For 'Physical Access', include 'OBD-II Port Exploit' and 'ECU Extraction'. Expand 'OBD-II Port Exploit' with 'Sniffing Traffic' and 'Sending Commands'. Expand 'ECU Extraction' with 'Direct Flash Access' and 'Hardware Debugging Interface'.\n","\n","Make sure:\n","- All node labels are short and readable (no long sentences)\n","- Use unique node IDs or Mermaid-friendly naming (avoid duplicate text nodes)\n","- No overlapping concepts\n","- Output is valid Mermaid syntax\n","\n","Output the full attack tree **only** in valid Mermaid code, wrapped in triple backticks like this:\n","\n","```mermaid\n","graph TD\n","\"\"\"\n","\n","        )\n","    }\n","]\n","\n","# 2. Load additional prompts from a local JSON file (if provided)\n","def load_prompts_from_file(file_path):\n","    try:\n","        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","            data = json.load(f)\n","            if isinstance(data, list):\n","                return data\n","            else:\n","                print(\"⚠️ JSON file must contain a list of prompts.\")\n","                return []\n","    except Exception as e:\n","        print(f\"❌ Error reading JSON file: {e}\")\n","        return []\n","\n","# 3. Merge predefined prompts with JSON prompts\n","json_prompts = load_prompts_from_file(\"ATT2.json\")  # Update path if needed\n","all_prompts = predefined_prompts + json_prompts\n","\n","# 4. Insert or update all prompts\n","for item in all_prompts:\n","    if \"label\" in item and \"prompt\" in item:\n","        prompt_library.update_one(\n","            {\"label\": item[\"label\"]},\n","            {\"$set\": item},\n","            upsert=True\n","        )\n","    else:\n","        print(f\"⚠️ Skipping invalid prompt entry: {item}\")\n","\n","print(\"✅ Prompt library with aliases populated successfully.\")\n"],"metadata":{"id":"Qbx1gfKiJL22"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"60mXqHAULkGd"}},{"cell_type":"markdown","source":["user interface"],"metadata":{"id":"crSFW_UEMKmq"}},{"cell_type":"code","source":["# ========================\n","# 📦 Library Imports\n","# ========================\n","import openai\n","from openai import OpenAI\n","import gradio as gr\n","from pymongo import MongoClient\n","from datetime import datetime\n","import re\n","import csv\n","import os\n","import pandas as pd\n","from collections import defaultdict, deque\n","\n","# ========================\n","# 🔐 API & DB Config\n","# ========================\n","OPENAI_API_KEY = # Replace with your OpenAI key\n","MONGODB_URI =# Replace with your MONGODB uri\n","\n","client_ai = OpenAI(api_key=OPENAI_API_KEY)\n","mongo_client = MongoClient(MONGODB_URI)\n","db = mongo_client[\"threat_db\"]\n","attack_tree_collection = db[\"attack_trees\"]\n","prompt_library = db[\"prompt_library\"]\n","\n","EXPORT_DIR = \"csv_exports\"\n","os.makedirs(EXPORT_DIR, exist_ok=True)\n","\n","# ========================\n","# 🔧 Utility Functions\n","# ========================\n","\n","def parse_mermaid_to_named_edges(mermaid_code):\n","    node_labels = {}\n","    edges = []\n","    lines = mermaid_code.splitlines()\n","    for line in lines:\n","        node_match = re.findall(r'(\\w+)\\[(.+?)\\]', line)\n","        for node_id, label in node_match:\n","            node_labels[node_id.strip()] = label.strip()\n","    edge_pattern = re.compile(r'(\\w+)\\s*-->\\s*(\\w+)')\n","    for line in lines:\n","        match = edge_pattern.search(line)\n","        if match:\n","            parent_id = match.group(1).strip()\n","            child_id = match.group(2).strip()\n","            parent_label = node_labels.get(parent_id, parent_id)\n","            child_label = node_labels.get(child_id, child_id)\n","            edges.append((parent_label, child_label))\n","    return edges\n","\n","def build_ordered_paths(edges):\n","    tree = defaultdict(list)\n","    indegree = defaultdict(int)\n","    for parent, child in edges:\n","        tree[parent].append(child)\n","        indegree[child] += 1\n","    roots = set(tree.keys()) - set(indegree.keys())\n","    if not roots:\n","        return []\n","    root = list(roots)[0]\n","    paths = []\n","    queue = deque([(root, [root])])\n","    while queue:\n","        node, path = queue.popleft()\n","        if node not in tree:\n","            paths.append(path)\n","        else:\n","            for child in tree[node]:\n","                queue.append((child, path + [child]))\n","    return paths\n","\n","def export_structured_csv(label, paths):\n","    safe_label = label[:30].replace(' ', '_').replace('/', '_')\n","    filename = f\"{safe_label}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv\"\n","    filepath = os.path.join(EXPORT_DIR, filename)\n","    with open(filepath, mode='w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\"Surface Goal\", \"Attack Vector\", \"Technique\", \"Method\", \"Path\"])\n","        for path in paths:\n","            row = path[:4] + [\" > \".join(path)]\n","            while len(row) < 5:\n","                row.insert(len(row) - 1, \"\")\n","            writer.writerow(row)\n","    return filepath\n","\n","def read_csv_as_dataframe(filepath):\n","    try:\n","        df = pd.read_csv(filepath)\n","        df.drop_duplicates(subset=[\"Path\"], inplace=True)\n","        return df\n","    except Exception:\n","        return pd.DataFrame(columns=[\"Surface Goal\", \"Attack Vector\", \"Technique\", \"Method\", \"Path\"])\n","\n","# ========================\n","# 📌 Tab 1: Generate from Label\n","# ========================\n","def generate_attack_tree_from_label(label_selected):\n","    if not label_selected:\n","        return \"❌ Select a threat scenario.\"\n","    doc = prompt_library.find_one({\"label\": label_selected}) or prompt_library.find_one({\"aliases\": {\"$in\": [label_selected.lower()]}})\n","    if not doc or \"prompt\" not in doc:\n","        return f\"❌ No prompt or alias found for '{label_selected}'\"\n","    matched_prompt = doc[\"prompt\"]\n","    label_to_save = doc[\"label\"]\n","    try:\n","        system_message = {\n","            \"role\": \"system\",\n","            \"content\": \"You are a cybersecurity expert. Return only the attack tree in Mermaid format using:\\n```mermaid\\ngraph TD\\n...```\"\n","        }\n","        response = client_ai.chat.completions.create(\n","            model=\"gpt-4-turbo\",\n","            messages=[system_message, {\"role\": \"user\", \"content\": matched_prompt}],\n","            temperature=0.3,\n","            max_tokens=1500\n","        )\n","        raw = response.choices[0].message.content.strip()\n","        match = re.search(r\"```mermaid\\s*(graph TD[\\s\\S]*?)```\", raw)\n","        if not match:\n","            return \"❌ Mermaid diagram not found or invalid format.\"\n","        mermaid_code = match.group(1).strip()\n","        attack_tree_collection.update_one(\n","            {\"label\": label_to_save},\n","            {\"$set\": {\n","                \"prompt\": matched_prompt,\n","                \"mermaid_code\": mermaid_code,\n","                \"updated_at\": datetime.utcnow()\n","            }},\n","            upsert=True\n","        )\n","        return f\"```mermaid\\n{mermaid_code}\\n```\"\n","    except Exception as e:\n","        return f\"❌ Error: {str(e)}\"\n","\n","# ========================\n","# 📜 Tab 2: View Stored Trees\n","# ========================\n","def wrapper_load(label):\n","    if not label:\n","        return \"❌ Select a saved attack tree.\", pd.DataFrame(), None\n","    doc = attack_tree_collection.find_one({\"label\": label}) or prompt_library.find_one({\"aliases\": {\"$in\": [label.lower()]}})\n","    if doc and \"label\" in doc and \"mermaid_code\" not in doc:\n","        return generate_attack_tree_from_label(doc[\"label\"]), pd.DataFrame(), None\n","    if not doc or \"mermaid_code\" not in doc:\n","        return \"❌ No stored attack tree found.\", pd.DataFrame(), None\n","    mermaid_code = doc[\"mermaid_code\"]\n","    edges = parse_mermaid_to_named_edges(mermaid_code)\n","    paths = build_ordered_paths(edges)\n","    csv_path = export_structured_csv(doc[\"label\"], paths)\n","    df = read_csv_as_dataframe(csv_path)\n","    return f\"```mermaid\\n{mermaid_code}\\n```\", df, csv_path\n","\n","# ========================\n","# 📾 Tab 3: Free Prompt\n","# ========================\n","def generate_tree_from_free_prompt(prompt):\n","    if not prompt.strip():\n","        return \"❌ Please enter a valid prompt\"\n","    try:\n","        all_docs = list(prompt_library.find({}, {\"label\": 1, \"aliases\": 1, \"prompt\": 1, \"_id\": 0}))\n","        matched_doc = None\n","        for doc in all_docs:\n","            if \"label\" not in doc:\n","                continue\n","            label = doc[\"label\"].lower()\n","            aliases = [a.lower() for a in doc.get(\"aliases\", [])]\n","            if label in prompt.lower() or any(alias in prompt.lower() for alias in aliases):\n","                matched_doc = doc\n","                break\n","\n","        if matched_doc:\n","            base_prompt = matched_doc[\"prompt\"]\n","            label_to_save = matched_doc[\"label\"]\n","            extended_prompt = f\"{base_prompt}\\n\\n# Extension:\\n{prompt}\"\n","            system_msg = {\n","                \"role\": \"system\",\n","                \"content\": \"You are a cybersecurity expert. Return the full updated attack tree in Mermaid format:\\n```mermaid\\ngraph TD\\n...```\"\n","            }\n","            response = client_ai.chat.completions.create(\n","                model=\"gpt-4-turbo\",\n","                messages=[system_msg, {\"role\": \"user\", \"content\": extended_prompt}],\n","                temperature=0.3,\n","                max_tokens=1200\n","            )\n","            raw = response.choices[0].message.content.strip()\n","            match = re.search(r\"```mermaid\\s*(graph TD[\\s\\S]*?)```\", raw)\n","            if not match:\n","                return \"❌ Mermaid diagram not found or invalid format.\"\n","            mermaid_code = match.group(1).strip()\n","\n","            attack_tree_collection.update_one(\n","                {\"label\": label_to_save},\n","                {\"$set\": {\"prompt\": extended_prompt, \"mermaid_code\": mermaid_code, \"updated_at\": datetime.utcnow()}},\n","                upsert=True\n","            )\n","            prompt_library.update_one(\n","                {\"label\": label_to_save},\n","                {\"$set\": {\"prompt\": extended_prompt, \"updated_at\": datetime.utcnow()}},\n","                upsert=True\n","            )\n","            return f\"```mermaid\\n{mermaid_code}\\n```\"\n","\n","        label_resp = client_ai.chat.completions.create(\n","            model=\"gpt-4-turbo\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"Generate a short, descriptive lowercase label (2–4 words) for this cybersecurity attack surface or scenario.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ],\n","            max_tokens=12,\n","            temperature=0.3\n","        )\n","        new_label = label_resp.choices[0].message.content.strip().lower().replace(\" \", \"_\")\n","\n","        alias_resp = client_ai.chat.completions.create(\n","            model=\"gpt-4-turbo\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"Give 3–5 short aliases or alternative names for the following cybersecurity concept or attack surface. Return only a Python list.\"},\n","                {\"role\": \"user\", \"content\": new_label.replace(\"_\", \" \")}\n","            ],\n","            max_tokens=100,\n","            temperature=0.5\n","        )\n","        try:\n","            alias_text = alias_resp.choices[0].message.content.strip()\n","            alias_list = eval(alias_text) if alias_text.startswith(\"[\") else [new_label]\n","            alias_list = [a.lower().strip() for a in alias_list if a.strip()]\n","            if new_label not in alias_list:\n","                alias_list.append(new_label)\n","        except:\n","            alias_list = [new_label]\n","\n","        tree_resp = client_ai.chat.completions.create(\n","            model=\"gpt-4-turbo\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"Generate a full attack tree for the following prompt in Mermaid format starting with:\\n```mermaid\\ngraph TD\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ],\n","            temperature=0.3,\n","            max_tokens=1500\n","        )\n","        raw_tree = tree_resp.choices[0].message.content.strip()\n","        match = re.search(r\"```mermaid\\s*(graph TD[\\s\\S]*?)```\", raw_tree)\n","        if not match:\n","            return \"❌ Mermaid diagram not found or invalid format.\"\n","        mermaid_code = match.group(1).strip()\n","\n","        prompt_library.insert_one({\n","            \"label\": new_label,\n","            \"aliases\": alias_list,\n","            \"prompt\": prompt,\n","            \"created_at\": datetime.utcnow()\n","        })\n","        attack_tree_collection.insert_one({\n","            \"label\": new_label,\n","            \"prompt\": prompt,\n","            \"mermaid_code\": mermaid_code,\n","            \"created_at\": datetime.utcnow()\n","        })\n","\n","        return f\"```mermaid\\n{mermaid_code}\\n```\"\n","\n","    except Exception as e:\n","        return f\"❌ Error: {str(e)}\"\n","\n","# ========================\n","# 🚀 Dropdown Refresher\n","# ========================\n","def get_all_labels():\n","    return sorted([doc[\"label\"] for doc in prompt_library.find({}, {\"label\": 1})])\n","\n","def get_stored_labels():\n","    return sorted(set([doc[\"label\"] for doc in attack_tree_collection.find({\"label\": {\"$exists\": True}})]))\n","\n","def refresh_dropdowns():\n","    return gr.update(choices=get_all_labels()), gr.update(choices=get_stored_labels())\n","\n","# ========================\n","# 🎨 Gradio UI\n","# ========================\n","with gr.Blocks() as demo:\n","    with gr.Tab(\"🧠 Generate Attack Tree\"):\n","        gr.Markdown(\"### 🔐 attack tree\")\n","        label_dropdown = gr.Dropdown(choices=[], label=\"📌 Select or Type\", interactive=True, allow_custom_value=True)\n","        generate_button = gr.Button(\"🚀 Generate Attack Tree\")\n","        mermaid_display = gr.Markdown(label=\"📈 Generated Attack Tree\")\n","        generate_button.click(fn=generate_attack_tree_from_label, inputs=label_dropdown, outputs=mermaid_display)\n","\n","    with gr.Tab(\"📂 Library\"):\n","        gr.Markdown(\"### 📉 View and Export Structured Threat Trees\")\n","        saved_dropdown = gr.Dropdown(choices=[], label=\"📌 Select Stored Tree\", interactive=True, allow_custom_value=True)\n","        mermaid_output = gr.Markdown(label=\"📈 Saved Attack Tree\")\n","        relation_table = gr.Dataframe(headers=[\"Surface Goal\", \"Attack Vector\", \"Technique\", \"Method\", \"Path\"], datatype=[\"str\"]*5, interactive=False)\n","        download_button = gr.File(label=\"📅 Download CSV\")\n","        regen_button = gr.Button(\"🔄 Regenerate Tree from Prompt\")\n","        saved_dropdown.change(fn=wrapper_load, inputs=saved_dropdown, outputs=[mermaid_output, relation_table, download_button])\n","        regen_button.click(fn=generate_attack_tree_from_label, inputs=saved_dropdown, outputs=mermaid_output)\n","\n","    with gr.Tab(\"🗓️ Custom Prompt\"):\n","        gr.Markdown(\"🔍 Explore and Extend Threat Trees\")\n","        prompt_input = gr.Textbox(label=\"Enter your Custom Prompt\", lines=5, placeholder=\"e.g. Add another attack vector to CAN Bus\")\n","        custom_mermaid_output = gr.Markdown(label=\"📌 Extended Attack Tree\")\n","        submit_button = gr.Button(\"Generate and Update Tree\")\n","        submit_button.click(fn=generate_tree_from_free_prompt, inputs=prompt_input, outputs=custom_mermaid_output).then(\n","            fn=refresh_dropdowns, inputs=[], outputs=[label_dropdown, saved_dropdown]\n","        )\n","\n","    # ⏫ Load choices on app startup\n","    demo.load(fn=refresh_dropdowns, inputs=[], outputs=[label_dropdown, saved_dropdown])\n","\n","demo.launch(share=True)\n"],"metadata":{"id":"Odc4QA-BJRpT"},"execution_count":null,"outputs":[]}]}